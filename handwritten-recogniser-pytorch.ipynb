{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10759588,"sourceType":"datasetVersion","datasetId":6674098}],"dockerImageVersionId":30887,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"###  \nHandwritten character Recogniser","metadata":{}},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T18:10:17.932611Z","iopub.execute_input":"2025-02-18T18:10:17.932812Z","iopub.status.idle":"2025-02-18T18:10:24.045139Z","shell.execute_reply.started":"2025-02-18T18:10:17.932791Z","shell.execute_reply":"2025-02-18T18:10:24.044435Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\n\n# Define dataset path\ndataset_path = \"/kaggle/input/hand-dataset\"  # Ensure this path is correct\nIMG_SIZE = 32  # Image resize dimensions\n\n# Get class names and create label mapping\nclass_names = sorted(os.listdir(dataset_path))  # Sorted for consistency\nLABEL_MAP = {name: idx for idx, name in enumerate(class_names)}\n\nprint(f\"‚úÖ Found {len(class_names)} classes: {class_names}\")\n\n# Custom dataset class\nclass HandwritingDataset(Dataset):\n    def __init__(self, image_paths, labels, transform=None):\n        self.image_paths = image_paths\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, index):\n        img_path = self.image_paths[index]\n        label = self.labels[index]\n\n        # Read image in grayscale\n        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        if img is None:\n            raise ValueError(f\"‚ö†Ô∏è Error loading image: {img_path}\")\n\n        # Resize and normalize\n        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n        img = np.expand_dims(img, axis=0)  # Add channel dimension (1, H, W)\n        img = img.astype(np.float32) / 255.0  # Normalize\n\n        if self.transform:\n            img = self.transform(img)\n\n        return torch.tensor(img, dtype=torch.float32), torch.tensor(label, dtype=torch.long)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T18:18:16.916765Z","iopub.execute_input":"2025-02-18T18:18:16.917129Z","iopub.status.idle":"2025-02-18T18:18:16.925313Z","shell.execute_reply.started":"2025-02-18T18:18:16.917100Z","shell.execute_reply":"2025-02-18T18:18:16.924421Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Found 62 classes: ['0', '1', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '2', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '3', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '4', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '5', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59', '6', '60', '61', '7', '8', '9']\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# Load dataset\nimage_paths = []\nlabels = []\n\nfor class_name in tqdm(class_names, desc=\"Loading Images\"):\n    class_path = os.path.join(dataset_path, class_name)\n    if not os.path.isdir(class_path):\n        continue\n\n    for img_name in os.listdir(class_path):\n        img_path = os.path.join(class_path, img_name)\n        image_paths.append(img_path)\n        labels.append(LABEL_MAP[class_name])\n\n# Train-test split\nX_train, X_test, y_train, y_test = train_test_split(image_paths, labels, test_size=0.2, random_state=42, stratify=labels)\n\n# Transformations\ntransform = transforms.Compose([\n    transforms.ToTensor()\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T18:18:26.646767Z","iopub.execute_input":"2025-02-18T18:18:26.647109Z","iopub.status.idle":"2025-02-18T18:18:26.743929Z","shell.execute_reply.started":"2025-02-18T18:18:26.647080Z","shell.execute_reply":"2025-02-18T18:18:26.743227Z"}},"outputs":[{"name":"stderr","text":"Loading Images: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 62/62 [00:00<00:00, 723.39it/s]\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Create PyTorch datasets\ntrain_dataset = HandwritingDataset(X_train, y_train, transform=transform)\ntest_dataset = HandwritingDataset(X_test, y_test, transform=transform)\n\n# Data loaders\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\nprint(f\"‚úÖ Dataset Loaded: Training Samples={len(train_dataset)}, Testing Samples={len(test_dataset)}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-18T18:18:32.016847Z","iopub.execute_input":"2025-02-18T18:18:32.017168Z","iopub.status.idle":"2025-02-18T18:18:32.022453Z","shell.execute_reply.started":"2025-02-18T18:18:32.017142Z","shell.execute_reply":"2025-02-18T18:18:32.021608Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Dataset Loaded: Training Samples=2728, Testing Samples=682\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"# Function to calculate accuracy\ndef calculate_accuracy(model, dataloader, criterion, device):\n    model.eval()  # Set model to evaluation mode\n    correct = 0\n    total = 0\n    total_loss = 0.0\n\n    with torch.no_grad():  # No gradient calculation for validation\n        for images, labels in dataloader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            total_loss += loss.item()\n\n            _, predicted = torch.max(outputs, 1)  # Get predicted class\n            correct += (predicted == labels).sum().item()\n            total += labels.size(0)\n\n    accuracy = (correct / total) * 100\n    avg_loss = total_loss / len(dataloader)\n    return accuracy, avg_loss\n\n\n# Training loop with accuracy & loss tracking\nEPOCHS = 20\nfor epoch in range(EPOCHS):\n    model.train()\n    running_loss = 0.0\n    correct_train = 0\n    total_train = 0\n\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n        _, predicted = torch.max(outputs, 1)\n        correct_train += (predicted == labels).sum().item()\n        total_train += labels.size(0)\n\n    # Calculate training accuracy and average loss\n    train_accuracy = (correct_train / total_train) * 100\n    train_loss = running_loss / len(train_loader)\n\n    # Calculate validation accuracy and loss\n    val_accuracy, val_loss = calculate_accuracy(model, test_loader, criterion, device)\n\n    print(f\"Epoch [{epoch+1}/{EPOCHS}]\")\n    print(f\"  üèãÔ∏è‚Äç‚ôÇÔ∏è Training  - Loss: {train_loss:.4f}, Accuracy: {train_accuracy:.2f}%\")\n    print(f\"  üìä Validation - Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.2f}%\\n\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T04:44:32.862040Z","iopub.execute_input":"2025-02-19T04:44:32.862453Z","iopub.status.idle":"2025-02-19T04:45:58.034959Z","shell.execute_reply.started":"2025-02-19T04:44:32.862424Z","shell.execute_reply":"2025-02-19T04:45:58.034053Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/20]\n  üèãÔ∏è‚Äç‚ôÇÔ∏è Training  - Loss: 0.6174, Accuracy: 78.52%\n  üìä Validation - Loss: 0.8619, Accuracy: 73.75%\n\nEpoch [2/20]\n  üèãÔ∏è‚Äç‚ôÇÔ∏è Training  - Loss: 0.5793, Accuracy: 79.40%\n  üìä Validation - Loss: 0.8857, Accuracy: 72.14%\n\nEpoch [3/20]\n  üèãÔ∏è‚Äç‚ôÇÔ∏è Training  - Loss: 0.5491, Accuracy: 79.95%\n  üìä Validation - Loss: 0.8561, Accuracy: 74.49%\n\nEpoch [4/20]\n  üèãÔ∏è‚Äç‚ôÇÔ∏è Training  - Loss: 0.5237, Accuracy: 81.01%\n  üìä Validation - Loss: 0.8887, Accuracy: 73.31%\n\nEpoch [5/20]\n  üèãÔ∏è‚Äç‚ôÇÔ∏è Training  - Loss: 0.5106, Accuracy: 81.60%\n  üìä Validation - Loss: 0.8894, Accuracy: 73.75%\n\nEpoch [6/20]\n  üèãÔ∏è‚Äç‚ôÇÔ∏è Training  - Loss: 0.5001, Accuracy: 81.96%\n  üìä Validation - Loss: 0.8986, Accuracy: 74.05%\n\nEpoch [7/20]\n  üèãÔ∏è‚Äç‚ôÇÔ∏è Training  - Loss: 0.5014, Accuracy: 82.62%\n  üìä Validation - Loss: 0.9051, Accuracy: 73.31%\n\nEpoch [8/20]\n  üèãÔ∏è‚Äç‚ôÇÔ∏è Training  - Loss: 0.4592, Accuracy: 83.47%\n  üìä Validation - Loss: 0.9319, Accuracy: 73.61%\n\nEpoch [9/20]\n  üèãÔ∏è‚Äç‚ôÇÔ∏è Training  - Loss: 0.4436, Accuracy: 84.05%\n  üìä Validation - Loss: 0.9361, Accuracy: 73.31%\n\nEpoch [10/20]\n  üèãÔ∏è‚Äç‚ôÇÔ∏è Training  - Loss: 0.3975, Accuracy: 85.92%\n  üìä Validation - Loss: 0.9472, Accuracy: 73.02%\n\nEpoch [11/20]\n  üèãÔ∏è‚Äç‚ôÇÔ∏è Training  - Loss: 0.3816, Accuracy: 86.73%\n  üìä Validation - Loss: 1.0444, Accuracy: 73.75%\n\nEpoch [12/20]\n  üèãÔ∏è‚Äç‚ôÇÔ∏è Training  - Loss: 0.4228, Accuracy: 84.27%\n  üìä Validation - Loss: 0.9733, Accuracy: 73.90%\n\nEpoch [13/20]\n  üèãÔ∏è‚Äç‚ôÇÔ∏è Training  - Loss: 0.3896, Accuracy: 85.34%\n  üìä Validation - Loss: 1.0246, Accuracy: 72.43%\n\nEpoch [14/20]\n  üèãÔ∏è‚Äç‚ôÇÔ∏è Training  - Loss: 0.3885, Accuracy: 85.78%\n  üìä Validation - Loss: 0.9898, Accuracy: 74.34%\n\nEpoch [15/20]\n  üèãÔ∏è‚Äç‚ôÇÔ∏è Training  - Loss: 0.3716, Accuracy: 85.96%\n  üìä Validation - Loss: 0.9989, Accuracy: 74.49%\n\nEpoch [16/20]\n  üèãÔ∏è‚Äç‚ôÇÔ∏è Training  - Loss: 0.3419, Accuracy: 87.13%\n  üìä Validation - Loss: 1.0009, Accuracy: 75.51%\n\nEpoch [17/20]\n  üèãÔ∏è‚Äç‚ôÇÔ∏è Training  - Loss: 0.3212, Accuracy: 87.90%\n  üìä Validation - Loss: 1.0370, Accuracy: 73.46%\n\nEpoch [18/20]\n  üèãÔ∏è‚Äç‚ôÇÔ∏è Training  - Loss: 0.3110, Accuracy: 88.42%\n  üìä Validation - Loss: 1.0227, Accuracy: 76.10%\n\nEpoch [19/20]\n  üèãÔ∏è‚Äç‚ôÇÔ∏è Training  - Loss: 0.3095, Accuracy: 88.23%\n  üìä Validation - Loss: 1.0494, Accuracy: 75.07%\n\nEpoch [20/20]\n  üèãÔ∏è‚Äç‚ôÇÔ∏è Training  - Loss: 0.3043, Accuracy: 89.55%\n  üìä Validation - Loss: 1.0981, Accuracy: 75.51%\n\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Save model\ntorch.save(model.state_dict(), \"handwritten_characters_model_recogniser.pth\")\nprint(\"‚úÖ Model training complete & saved!\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-19T04:48:02.315002Z","iopub.execute_input":"2025-02-19T04:48:02.315303Z","iopub.status.idle":"2025-02-19T04:48:02.326544Z","shell.execute_reply.started":"2025-02-19T04:48:02.315283Z","shell.execute_reply":"2025-02-19T04:48:02.325679Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Model training complete & saved!\n","output_type":"stream"}],"execution_count":7}]}